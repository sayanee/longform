---
layout: post
title:  "An Ethical Framework for Evaluating Experimental Technology?"
source: https://pubmed.ncbi.nlm.nih.gov/26573302/
category: research paper
author: Ibo van de Poel
---

<!-- START doctoc generated TOC please keep comment here to allow auto update -->
<!-- DON'T EDIT THIS SECTION, INSTEAD RE-RUN doctoc TO UPDATE -->
**Table of Contents**

- [Nature of experimental technologies](#nature-of-experimental-technologies)
- [Definitions](#definitions)
- [How to use experimental technologies](#how-to-use-experimental-technologies)

<!-- END doctoc generated TOC please keep comment here to allow auto update -->

## Nature of experimental technologies

Conventional approach to technological developments

> How are we to appraise new technological developments that may bring revolutionary social changes? Currently this is often done by **trying to predict or anticipate social consequences** and to use these as a basis for moral and regulatory appraisal.

Hard to predict

> Swarm robots. Human enhancement. Algae based on synthetic biology. Automated driving vehicles. What these new technological possibilities have in common is that **they may seriously impact society, for the good as well as for the bad**. What they also have in common is that the **exact impacts on society are currently largely unknown and are very hard to predict beforehand**.

Evidence-based or precautionary-based

> the current moral and regulatory appraisal of such technologies is often either based on **what we know and can scientifically prove (in so-called science-based or evidence-based approaches)** or on scenarios that might occur but of which **the probability is unknown (in so-called precautionary approaches)**. Both types of approaches, however, run a risk of missing out on important actual social consequences of new technologies and of making us blind to surprises. Therefore, both approaches do not really address the uncertainty that is inherent in the introduction of new technology into society.

Shortcomings of predictive methods

> predictive methods (e.g., risk assessment, cost-benefit analysis, climate modelling) that are designed, on the whole, to facilitate management and control, even in areas of high uncertainty’. Such predictive methods, however, have three shortcomings according to her. First, they **deny uncertainty and ignorance**; second, they **short-circuit the moral dimension of new technological developments**; third, **they do not address the need for profound (social) learning from, for example, errors and catastrophes**. As an alternative, she proposes the development of what she calls ‘technologies of humility,’ which address issues of **framing, vulnerability, distribution, and learning**.

## Definitions

An ethical framework for the acceptability of such experiments:

- non-maleficence
- beneficence
- respect for autonomy
- justice

What is an experimental technology?

> I will call technologies experimental if **there is only limited operational experience with them**, so that social benefits and risks cannot, or at least not straightforwardly, be assessed on basis of experience... Still, the introduction of such technologies into society comes with **large uncertainties, unknowns and indeterminacies** that are often only reduced once such technologies are actually introduced into society.

## How to use experimental technologies

Operational experience

> Above I have suggested that **operational experience is an important factor** but how much and for how long a period, operational experience is required may well depend on the technology and the kind of (social) impacts one is interested in or worried about.

Early phase vs later phase

> This dilemma says that in the early phases of new technology, when a technology and its social embedding are still malleable, there is uncertainty about the social effects of that technology. In later phases, social effects may be clear but then often the technology has become so well entrenched in society that it is **hard to overcome negative social effects**.

Gradual and experimental introduction

> This alternative is the **gradual and experimental introduction of a technology into society**, in such a way that emerging social effects are monitored and are used to improve the technology and its introduction into society...Popper (1945) has argued for what he called **piecemeal social engineering, rather than revolutionary social change**.

Small, limited steps with trial and error

> He emphasized that due to our limited information-processing capacities and due to uncertainties and unknowns, we can usually not plan rationally but have ‘to muddle through’ (Lindblom 1959). The best we can do often is to proceed in small or limited steps and to learn from trial and error.

Incremental decision-making

> Collingridge (1992), for example, stresses the importance of trial-and-error learning, incremental decision-making, and flexibility and adaptability, and shows how a number of costly technical failures are due to a lack of such an approach.

Labs vs real world experiments

> As Albion Small expressed it: "All the laboratories in the world could not carry on enough experiments to measure a thimbleful compared with the world of experimentation open to the observation of social science. The radical difference is that the **laboratory scientists can arrange their own experiments** while we social scientists for the most part **have our experiments arranged for us**."

Problem with informed consent

> Martin and Schinzinger (1983, 1996) have proposed informed consent as a main ethical principle to judge the moral acceptability of social experiments with new technology...This problem is due to the fact that whereas in medicine, and in **clinical experiments, risks are usually borne individually**, in **technology risks may be individual as well as collective**.

An ethical framework for experimental technology:

1. Absence of other reasonable means for gaining knowledge about risks and benefits
1. Monitoring of data and risks while addressing privacy concerns
1. Possibility and willingness to adapt or stop the experiment
1. Containment of risks as far as reasonably possible
1. Consciously scaling up to avoid large-scale harm and to improve learning
1. Flexible set-up of the experiment and avoidance of lock-in of the technology
1. Avoid experiments that undermine resilience
1. Reasonable to expect social benefits from the experiment
1. Clear distribution of responsibilities for setting up, carrying out, monitoring, evaluating, adapting, and stopping of the experiment
1. Experimental subjects are informed
1. The experiment is approved by democratically legitimized bodies
1. Experimental subjects can influence the setting up, carrying out, monitoring, evaluating, adapting, and stopping of the experiment
1. Experimental subjects can withdraw from the experiment
1. Vulnerable experimental subjects are either not subject to the experiment or are additionally protected or particularly profit from the experimental technology (or a combination)
1. A fair distribution of potential hazards and benefits
1. Reversibility of harm or, if impossible, compensation of harm
